# TASK5
Decision Trees and Random Forests

ğŸ“Œ Objective:

To explore and evaluate tree-based machine learning models â€” Decision Trees and Random Forests â€” for a classification problem using the Heart Disease Health Indicators dataset.

ğŸ“‚ Dataset:

Heart Disease Health Indicators (BRFSS 2015)
Source: Kaggle Dataset

Binary classification: HeartDiseaseorAttack (1 = Yes, 0 = No)

Features include: BMI, Smoking, Physical Activity, HighBP, Diabetes, Mental Health, etc.


âœ… Key Tasks Completed:

1. Trained a Decision Tree Classifier:

Used scikit-learn to build the model.

Target variable: HeartDiseaseorAttack.

Visualized the tree structure using Graphviz.



2. Analyzed Overfitting:

Controlled tree complexity with max_depth, min_samples_split.

Observed accuracy trade-offs with pruning.



3. Trained a Random Forest Classifier:

Compared accuracy and generalization with the Decision Tree.

Found improved performance through ensembling.



4. Interpreted Feature Importances:

Used .feature_importances_ to identify key predictors.



5. Cross-Validation Evaluation:

Applied 5-fold cross-validation using cross_val_score.

Reported fold-wise and average accuracy.

ğŸ› ï¸ Tools & Libraries Used:

Python

Pandas

Scikit-learn

Graphviz

Matplotlib / Seaborn (optional for visualizations)

ğŸ“ˆ Sample Results:

Decision Tree Accuracy: ~74%

Random Forest Accuracy: ~78â€“80%

Important Features: HighBP, BMI, Smoking, Age, Physical Activity

ğŸ” Insights:

Random Forests reduce overfitting and perform better on unseen data.

Feature importance helps in understanding key health indicators influencing heart disease.

